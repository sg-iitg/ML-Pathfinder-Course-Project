{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import struct\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            binary = w_f.read()\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    " \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    " \n",
    "    def load_weights(self, model):\n",
    "        by_name=True\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "                    beta  = self.read_bytes(size) # bias\n",
    "                    gamma = self.read_bytes(size) # scale\n",
    "                    mean  = self.read_bytes(size) # mean\n",
    "                    var   = self.read_bytes(size) # variance\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))\n",
    " \n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    for conv in convs:\n",
    "        if count == len(convs) - 2 and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        if conv['stride'] > 1:  # peculiar padding as darknet prefer left and top\n",
    "            x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "        x = Conv2D(  # peculiar padding as darknet prefer left and top\n",
    "            conv['filter'],\n",
    "            conv['kernel'],\n",
    "            strides=conv['stride'],\n",
    "            padding=('valid' if conv['stride'] > 1 else 'same'),\n",
    "            name='conv_' + str(conv['layer_idx']),\n",
    "            use_bias=(False if conv['bnorm'] else True),\n",
    "            )(x)\n",
    "        if conv['bnorm']:\n",
    "            x = BatchNormalization(epsilon=0.001, name='bnorm_'\n",
    "                                   + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']:\n",
    "            x = LeakyReLU(alpha=0.1, name='leaky_'\n",
    "                          + str(conv['layer_idx']))(x)\n",
    "    return (add([skip_connection, x]) if skip else x)\n",
    "\n",
    "\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "\n",
    "    x = _conv_block(input_image, [{\n",
    "        'filter': 32,\n",
    "        'kernel': 3,\n",
    "       \n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 0,\n",
    "        }, {\n",
    "        'filter': 64,\n",
    "        'kernel': 3,\n",
    "        'stride': 2,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 1,\n",
    "        }, {\n",
    "        'filter': 32,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 2,\n",
    "        }, {\n",
    "        'filter': 64,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 3,\n",
    "        }])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 128,\n",
    "        'kernel': 3,\n",
    "        'stride': 2,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 5,\n",
    "        }, {\n",
    "        'filter': 64,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 6,\n",
    "        }, {\n",
    "        'filter': 128,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 7,\n",
    "        }])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 64,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 9,\n",
    "        }, {\n",
    "        'filter': 128,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 10,\n",
    "        }])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 256,\n",
    "        'kernel': 3,\n",
    "        'stride': 2,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 12,\n",
    "        }, {\n",
    "        'filter': 128,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 13,\n",
    "        }, {\n",
    "        'filter': 256,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 14,\n",
    "        }])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{\n",
    "            'filter': 128,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 16 + i * 3,\n",
    "            }, {\n",
    "            'filter': 256,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 17 + i * 3,\n",
    "            }])\n",
    "    skip_36 = x\n",
    "\n",
    "    # Layer 37 => 40\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 512,\n",
    "        'kernel': 3,\n",
    "        'stride': 2,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 37,\n",
    "        }, {\n",
    "        'filter': 256,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 38,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 39,\n",
    "        }])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{\n",
    "            'filter': 256,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 41 + i * 3,\n",
    "            }, {\n",
    "            'filter': 512,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 42 + i * 3,\n",
    "            }])\n",
    "    skip_61 = x\n",
    "\n",
    "    # Layer 62 => 65\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 1024,\n",
    "        'kernel': 3,\n",
    "        'stride': 2,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 62,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 63,\n",
    "        }, {\n",
    "        'filter': 1024,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 64,\n",
    "        }])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{\n",
    "            'filter': 512,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 66 + i * 3,\n",
    "            }, {\n",
    "            'filter': 1024,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 67 + i * 3,\n",
    "            }])\n",
    "\n",
    "    # Layer 75 => 79\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 512,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 75,\n",
    "        }, {\n",
    "        'filter': 1024,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 76,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 77,\n",
    "        }, {\n",
    "        'filter': 1024,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 78,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 79,\n",
    "        }], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "\n",
    "    yolo_82 = _conv_block(x, [{\n",
    "        'filter': 1024,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 80,\n",
    "        }, {\n",
    "        'filter': 255,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': False,\n",
    "        'leaky': False,\n",
    "        'layer_idx': 81,\n",
    "        }], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 256,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 84,\n",
    "        }], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 256,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 87,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 88,\n",
    "        }, {\n",
    "        'filter': 256,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 89,\n",
    "        }, {\n",
    "        'filter': 512,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 90,\n",
    "        }, {\n",
    "        'filter': 256,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 91,\n",
    "        }], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "\n",
    "    yolo_94 = _conv_block(x, [{\n",
    "        'filter': 512,\n",
    "        'kernel': 3,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 92,\n",
    "        }, {\n",
    "        'filter': 255,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': False,\n",
    "        'leaky': False,\n",
    "        'layer_idx': 93,\n",
    "        }], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "\n",
    "    x = _conv_block(x, [{\n",
    "        'filter': 128,\n",
    "        'kernel': 1,\n",
    "        'stride': 1,\n",
    "        'bnorm': True,\n",
    "        'leaky': True,\n",
    "        'layer_idx': 96,\n",
    "        }], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "\n",
    "    yolo_106 = _conv_block(x, [\n",
    "        {\n",
    "            'filter': 128,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 99,\n",
    "            },\n",
    "        {\n",
    "            'filter': 256,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 100,\n",
    "            },\n",
    "        {\n",
    "            'filter': 128,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 101,\n",
    "            },\n",
    "        {\n",
    "            'filter': 256,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 102,\n",
    "            },\n",
    "        {\n",
    "            'filter': 128,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 103,\n",
    "            },\n",
    "        {\n",
    "            'filter': 256,\n",
    "            'kernel': 3,\n",
    "            'stride': 1,\n",
    "            'bnorm': True,\n",
    "            'leaky': True,\n",
    "            'layer_idx': 104,\n",
    "            },\n",
    "        {\n",
    "            'filter': 255,\n",
    "            'kernel': 1,\n",
    "            'stride': 1,\n",
    "            'bnorm': False,\n",
    "            'leaky': False,\n",
    "            'layer_idx': 105,\n",
    "            },\n",
    "        ], skip=False)\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n"
     ]
    }
   ],
   "source": [
    "# define the yolo v3 model\n",
    "yolov3 = make_yolov3_model()\n",
    "\n",
    "# load the weights\n",
    "weight_reader = WeightReader('yolov3.weights')\n",
    "\n",
    "# set the weights\n",
    "weight_reader.load_weights(yolov3)\n",
    "\n",
    "# save the model to file\n",
    "yolov3.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        xmin,\n",
    "        ymin,\n",
    "        xmax,\n",
    "        ymax,\n",
    "        objness=None,\n",
    "        classes=None,\n",
    "        ):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "        return self.get_score\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "def decode_netout(netout,anchors, obj_thresh, net_h, net_w):\n",
    "    (grid_h, grid_w) = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2] = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:] = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h * grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "\n",
    "            # 4th element is objectness score\n",
    "\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if objectness.all() <= obj_thresh:\n",
    "                continue\n",
    "\n",
    "            # first 4 elements are x, y, w, and h\n",
    "\n",
    "            (x, y, w, h) = (netout[int(row)][int(col)][b])[:4]\n",
    "            x = (col + x) / grid_w  # center position, unit: image width\n",
    "            y = (row + y) / grid_h  # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w  # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h  # unit: image height\n",
    "\n",
    "            # last elements are class probabilities\n",
    "\n",
    "            classes = (netout[int(row)][col][b])[5:]\n",
    "            box = BoundBox(\n",
    "                x - w / 2,\n",
    "                y - h / 2,\n",
    "                x + w / 2,\n",
    "                y + h / 2,\n",
    "                objectness,\n",
    "                classes,\n",
    "                )\n",
    "            boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_yolo_boxes(boxes,image_h,image_w,net_h,net_w):\n",
    "    (new_w, new_h) = (net_w, net_h)\n",
    "    for i in range(len(boxes)):\n",
    "        (x_offset, x_scale) = ((net_w - new_w) / 2. / net_w,  float(new_w) / net_w)\n",
    "        (y_offset, y_scale) = ((net_h - new_h) / 2. / net_h, float(new_h) / net_h)\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "        \n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin,\n",
    "                                    box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin,\n",
    "                                    box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    (w1, h1) = (box1.xmax - box1.xmin, box1.ymax - box1.ymin)\n",
    "    (w2, h2) = (box2.xmax - box2.xmin, box2.ymax - box2.ymin)\n",
    "    union = w1 * h1 + w2 * h2 - intersect\n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0:\n",
    "                continue\n",
    "            for j in range(i + 1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) \\\n",
    "                    >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "\n",
    "#get all of the results above a threshold\n",
    "\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    (v_boxes, v_labels, v_scores) = (list(), list(), list())\n",
    "\n",
    "    # enumerate all boxes\n",
    "\n",
    "    for box in boxes:\n",
    "\n",
    "        # enumerate all possible labels\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "\n",
    "            # check if the threshold for this label is high enough\n",
    "\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i] * 100)\n",
    "\n",
    "                # don't break, many labels may trigger for one box\n",
    "\n",
    "    return (v_boxes, v_labels, v_scores)\n",
    "\n",
    "\n",
    "#draw all results\n",
    "\n",
    "# def draw_boxes(\n",
    "#     frame,\n",
    "#     v_boxes,\n",
    "#     v_labels,\n",
    "#     v_scores,\n",
    "#     ):\n",
    "\n",
    "    \n",
    "#     # get the context for drawing boxes\n",
    "\n",
    "#     ax = pyplot.gca()\n",
    "\n",
    "#     # plot each box\n",
    "\n",
    "#     for i in range(len(v_boxes)):\n",
    "#         box = v_boxes[i]\n",
    "\n",
    "#         # get coordinates\n",
    "\n",
    "#         (y1, x1, y2, x2) = (box.ymin, box.xmin, box.ymax, box.xmax)\n",
    "\n",
    "#         # calculate width and height of the box\n",
    "\n",
    "#         (width, height) = (x2 - x1, y2 - y1)\n",
    "\n",
    "#         frame= cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "        \n",
    "#     cv2.imshow('frame', frame)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [[116, 90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "\n",
    "labels= [\"face\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed the below code appropriately to convert the frame into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed this to modify the frame \n",
    "from numpy import expand_dims\n",
    "def load_image_pixels(img, shape):\n",
    "    \n",
    "    image= Image.fromarray(img, 'RGB')\n",
    "    width, height= image.size\n",
    "    \n",
    "    image= image.resize(shape)\n",
    "    \n",
    "    # convert to numpy array\n",
    "    image = np.array(image)\n",
    " \n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    " \n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed the below code to capture real-time video and process each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n",
      "face 96.3959276676178\n",
      "106 6 514 633\n",
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n",
      "face 95.2061414718628\n",
      "112 -5 513 640\n",
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n",
      "face 91.7104184627533\n",
      "107 -1 518 637\n",
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n",
      "face 91.37458801269531\n",
      "107 0 516 635\n",
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n",
      "face 92.67258644104004\n",
      "107 1 516 631\n",
      "[(1, 5, 5, 255), (1, 10, 10, 255), (1, 20, 20, 255)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "input_w, input_h = 160, 160 \n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame= cap.read()\n",
    "    \n",
    "    image, image_w, image_h = load_image_pixels(frame, (input_w, input_h))\n",
    "\n",
    "    # make prediction\n",
    "\n",
    "    yhat = yolov3.predict(image)\n",
    "    \n",
    "    # summarize the shape of the list of arrays\n",
    "\n",
    "    print ([a.shape for a in yhat])\n",
    "\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "\n",
    "    # decode the output of the network\n",
    "\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_w, input_h)\n",
    "\n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "\n",
    "    #suppress non-maximal boxes\n",
    "\n",
    "    #yolo_non_max_suppresion()\n",
    "    do_nms(boxes, 0.5)\n",
    "\n",
    "    # # get the details of the detected objects\n",
    "\n",
    "    (v_boxes, v_labels, v_scores) = get_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "    # summarize what we found\n",
    "\n",
    "    for i in range(len(v_boxes)):\n",
    "        print (v_labels[i], v_scores[i])\n",
    "\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "\n",
    "        # get coordinates\n",
    "\n",
    "        (y1, x1, y2, x2) = (box.ymin, box.xmin, box.ymax, box.xmax)\n",
    "        \n",
    "        print(box.ymin, box.xmin, box.ymax, box.xmax)\n",
    "\n",
    "        # calculate width and height of the box\n",
    "\n",
    "        (width, height) = (x2 - x1, y2 - y1)\n",
    "\n",
    "        frame= cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "        text=\"face\"\n",
    "        cv2.putText(frame, text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1)== ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
